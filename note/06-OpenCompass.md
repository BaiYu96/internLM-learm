# 大模型评测

## 关于评测的三个问题

### 为什么要评测？

* 模型选型
* 模型能力提升
* 真实应用场景效果提升

![1706171986393](assets/1706171986393.png)

### 我们需要测什么

* 知识、推理、语言
* 长文本、智能体、多轮对话
* 情感、认知、价值观

![1706172248363](assets/1706172248363.png)

### 怎么样测试大语言模型

* 主观评测
* 客观评测
* 提示词工程



## 国内外测评体系

![1706172429017](assets/1706172429017.png)

## OpenCompass介绍

为全面反映大模型在不同领域的能力差异，客观反映优势与问题，OpenCompass将测评方向汇总为学科、语言、知识、理解、推理、安全6大能力维度，整合集纳了超过100+个评测数据集，合计提供了超过50万+个模型评测问题

![1706172475493](assets/1706172475493.png)

## 评测对象

OpenCompass算法库的主要评测对象为语言大模型与多模态大模型。

## 工具架构

![1706172545569](assets/1706172545569.png)

- 模型层：大模型评测所涉及的主要模型种类，OpenCompass以基座模型和对话模型作为重点评测对象。
- 能力层：OpenCompass从本方案从通用能力和特色能力两个方面来进行评测维度设计。在模型通用能力方面，从语言、知识、理解、推理、安全等多个能力维度进行评测。在特色能力方面，从长文本、代码、工具、知识增强等维度进行评测。
- 方法层：OpenCompass采用客观评测与主观评测两种评测方式。客观评测能便捷地评估模型在具有确定答案（如选择，填空，封闭式问答等）的任务上的能力，主观评测能评估用户对模型回复的真实满意度，OpenCompass采用基于模型辅助的主观评测和基于人类反馈的主观评测两种方式。
- 工具层：OpenCompass提供丰富的功能支持自动化地开展大语言模型的高效评测。包括分布式评测技术，提示词工程，对接评测数据库，评测榜单发布，评测报告生成等诸多功能。

## 大模型测评领域的挑战

* 缺少高质量中文评测集
* 难以准确提取答案
* 能力维度不足
* 测试集混入训练集
* 测试标准各异
* 人工测试成本高昂